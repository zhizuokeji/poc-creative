# 开发记录与心得

## 1. 整体思路：从探索到收敛

本项目的核心目标是构建一个高效、高质量的AI辅助内容创作工作流。其发展路径遵循了典型的探索性项目演进模式：从一个宏大、完备的顶层设计出发，通过实践和反思，逐步收敛到一套简洁、务实且高效的解决方案。

- **POC 探索阶段 (Proof of Concept)**: 初期，我借助辅助编程工具（如 Cline + Gemini 2.5 Pro）进行手动流程验证。此阶段的目标是打磨出一套高质量、分阶段的提示词工程（Prompt Engineering），并验证其在分离关注点、提升内容质量上的可行性。这个过程虽然成本较高，但为后续的自动化奠定了坚实的方法论基础。

- **工程化实现阶段**: 在验证了核心方法论后，我将这套经过打磨的提示词和工作流，通过一个Spring Boot应用进行固化和串联，旨在实现流程的自动化、标准化。

## 2. 架构演进：拥抱简单，回归本质

在工程化阶段，项目的架构经历了两次关键的重构，这体现了我对问题本质理解的不断深化。

### 第一次重构：从异步到同步，简化技术栈

项目初期，我采用了基于响应式编程（WebFlux）的异步模型，并设计了一套包含会话管理、状态机、异步处理的复杂工作流引擎。

- **反思**: 在实践中我发现，对于一个工具类、非高并发的后端应用，响应式编程带来的心智负担和代码复杂性，超过了其性能优势。
- **决策**: 我果断地移除了WebFlux，回归到传统的、基于Spring Web MVC的同步阻塞模型。这使得代码逻辑更直接，显著降低了复杂性，提升了可读性和可维护性。

### 第二次重构：从“工作流引擎”到“代码即流程”

随着开发的深入，我意识到，最初设计的“工作流引擎”存在过度工程（Over-engineering）的问题。

- **反思**: 一个由配置和状态机驱动的“黑盒”引擎，对于一个逻辑相对线性的创作流程来说过于笨重。流程的定义和修改不够透明和灵活。
- **决策**: 我废弃了整个工作流引擎的抽象，将其简化为一系列清晰、独立的Kotlin方法调用。整个创作流程由一个主方法 `createArticle` 按顺序调用各个阶段的子方法来完成。**流程的定义从复杂的外部配置，回归到了简单、直白的内部代码**。这是一种理念上的飞跃，它让系统变得极其透明、易于调试和扩展。

## 3. 核心突破：以“结构化数据”为中心的协作模式

项目最重要的突破，是将人机协作的中心从“控制流”转向了“数据流”。

- **问题**: 让大模型直接生成完整的、格式不定的Markdown文本，结果不稳定且难以进行程序化处理。
- **解决方案**: 我定义了一套严格的、贯穿始终的**JSON数据结构** (`ArticleContent`)。
  - **AI的职责**: AI不再是生成最终文本的“写手”，而是填充这个预定义JSON结构的“数据工程师”。从构思、写作到配图规划，AI的每一步输出都是严谨的、可被机器解析的JSON。
  - **程序的职责**: 程序则负责处理这些结构化数据。例如，在“配图执行”阶段，程序读取AI生成的JSON中的`imageDescription`字段，调用图片服务，然后将获取到的图片路径写回JSON的`imagePath`字段。在“完成”阶段，程序将最终的JSON数据渲染成用户所需的Markdown文件。

这种**“AI负责创造性填表，程序负责确定性执行”**的模式，为人机协作建立了一个稳定、可靠的接口，是整个系统得以高效、稳定运行的基石。

## 4. 测试与调试：YAML作为人机协作的桥梁

为了支持这种新的协作模式，我建立了一套独特的测试与调试机制。

- 在测试环境中，每个阶段生成的JSON数据都会被序列化为**YAML格式**并保存到磁盘。
- YAML相比JSON，对人类更加友好，易于阅读和修改。这使得开发者可以在任意两个阶段之间进行**人工干预**：检查AI生成的数据是否符合预期，甚至手动修改YAML文件中的内容，再启动下一阶段的测试。

这种以YAML为媒介的“断点调试”能力，极大地提升了在开发复杂AI工作流时的效率和可控性。

## 5. 总结与反思

回顾整个项目，我深刻体会到：

1. **警惕过度工程**: 始终选择与问题复杂度相匹配的最简解决方案。简单的、直接的代码往往比复杂的框架更强大。
2. **数据契约至上**: 在人机协作系统中，一个稳定、明确的数据交换格式，其重要性远超于复杂的流程控制逻辑。
3. **明确职责边界**: 精心设计AI和程序各自的角色和分工，让彼此的优势最大化，是项目成功的关键。
4. **迭代与勇气**: 不要害怕重构，更不要畏惧推翻自己最初的设计。在探索中不断迭代，逼近问题本质，这本身就是最有价值的过程。
